# benchmark_nlp.py

import time
import json
from pathlib import Path

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
# from codecarbon import EmissionsTracker  # optionnel : mesurer l'√©nergie consomm√©e

# ---------------------------------------------------------
# üî• Choix automatique du device : GPU Apple (mps), CUDA ou CPU
# ---------------------------------------------------------
if torch.backends.mps.is_available():
    DEVICE = "mps"         # GPU Apple (Mac M1/M2/M3)
elif torch.cuda.is_available():
    DEVICE = "cuda"        # GPU NVIDIA
else:
    DEVICE = "cpu"         # CPU
print("Using device:", DEVICE)

# üìÅ Dossiers de sortie et dossier du meilleur mod√®le
OUTPUT_DIR = Path("outputs")
BEST_MODEL_DIR = OUTPUT_DIR / "best_model"


# ---------------------------------------------------------
# ‚è±Ô∏è Fonction pour mesurer la latence moyenne d'inf√©rence
# ---------------------------------------------------------
@torch.no_grad()  # d√©sactive la grad, plus rapide et plus l√©ger
def measure_latency(model, tokenizer, text="This is a test sentence.", warmup=10, runs=100):
    """
    Mesure la latence en millisecondes d'une pr√©diction textuelle.
    
    - warmup : chauffe le mod√®le pour stabiliser les performances
    - runs   : nombre de mesures pour faire la moyenne
    """

    model.eval()  # mode √©valuation (d√©sactive dropout, etc.)

    # Tokenisation du texte d'entr√©e ‚Üí tenseurs PyTorch
    inputs = tokenizer(text, return_tensors="pt", truncation=True).to(DEVICE)

    # ---------------------------------------------------------
    # üî• Phase de warmup :
    # Premi√®re ex√©cution souvent plus lente (cache, initialisation GPU...)
    # ---------------------------------------------------------
    for _ in range(warmup):
        _ = model(**inputs)

    # Synchronisation GPU (si CUDA) ‚Üí garantit des mesures propres
    if DEVICE == "cuda":
        torch.cuda.synchronize()

    # ---------------------------------------------------------
    # üîç Mesure r√©elle de latence
    # ---------------------------------------------------------
    start = time.perf_counter()
    for _ in range(runs):
        _ = model(**inputs)
    if DEVICE == "cuda":
        torch.cuda.synchronize()
    end = time.perf_counter()

    # Moyenne en millisecondes
    avg_latency_ms = (end - start) / runs * 1000
    return avg_latency_ms


# ---------------------------------------------------------
# üöÄ Fonction principale
# ---------------------------------------------------------
def main():
    # Chargement du tokenizer et du mod√®le sauvegard√© dans train_nlp.py
    tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_DIR)
    model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_DIR).to(DEVICE)

    # ---------------------------------------------------------
    # ‚ö° (Optionnel) Mesure d'√©nergie via CodeCarbon
    # ---------------------------------------------------------
    # tracker = EmissionsTracker()
    # tracker.start()

    # Mesure de la latence
    latency_ms = measure_latency(model, tokenizer)

    # emissions = tracker.stop()  # kg CO2eq (si activ√©)

    print(f"‚è± Latence moyenne par requ√™te: {latency_ms:.3f} ms")

    # ---------------------------------------------------------
    # üìÑ Sauvegarde des m√©triques syst√®me (latence, √©nergie...)
    # dans outputs/system_metrics.json
    # ---------------------------------------------------------
    sys_metrics_path = OUTPUT_DIR / "system_metrics.json"
    data = {
        "latency_ms": latency_ms,
        # "emissions_kg": emissions  # si CodeCarbon activ√©
    }

    # Si un fichier existe d√©j√† ‚Üí fusion des donn√©es
    if sys_metrics_path.exists():
        with open(sys_metrics_path) as f:
            old = json.load(f)
        old.update(data)
        data = old

    # √âcriture JSON
    with open(sys_metrics_path, "w") as f:
        json.dump(data, f, indent=2)


# ---------------------------------------------------------
# ‚ñ∂Ô∏è Lancer le benchmark
# ---------------------------------------------------------
if __name__ == "__main__":
    main()
