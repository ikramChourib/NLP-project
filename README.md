ğŸš€ Projet NLP complet avec PyTorch â€“ Pipeline de bout en bout

Ce projet met en place un pipeline NLP complet, du dataset jusquâ€™au dÃ©ploiement API, en utilisant PyTorch, Transformers, et FastAPI.

ğŸ“¥ Dataset en ligne (HuggingFace)

Le projet utilise le dataset AG News directement depuis
datasets.load_dataset("ag_news").

ğŸ§  ModÃ¨le NLP : DistilBERT + PyTorch

Un modÃ¨le Transformer prÃ©-entraÃ®nÃ© (distilbert-base-uncased) est utilisÃ© pour :

la classification de texte

avec 4 classes (World, Sports, Business, Sci/Tech)

entraÃ®nÃ© via PyTorch (train_nlp.py)

ğŸ“Š Pipelines dâ€™Ã©valuation & mÃ©triques

Pendant lâ€™entraÃ®nement :

accuracy (train & validation)

loss (train & validation)

taille du modÃ¨le sauvegardÃ©

fichiers produits :

metrics.json (courbes d'entraÃ®nement)

system_metrics.json (latence, taille, Ã©nergieâ€¦)

âš¡ Benchmarking (benchmark_nlp.py)

Mesure :

latence moyenne (ms) par prÃ©diction

optionnel : Ã©nergie consommÃ©e via CodeCarbon

ğŸ“ˆ Dashboard Streamlit (dashboard_nlp.py)


Interface visuelle pour observer les mÃ©triques :

Courbes loss / accuracy

Mesures systÃ¨me :

latence

taille du modÃ¨le

Ã©nergie (optionnelle)

Outputs :

ğŸ“Š Dashboard entraÃ®nement :
![Dashboard NLP](images/dashborad.png)




ğŸ“‰ Mesures systÃ¨me
![measures NLP](images/measures.png)



ğŸŒ DÃ©ploiement via API (FastAPI)

Lâ€™API (api_nlp.py) permet dâ€™envoyer un texte et de recevoir :

le label prÃ©dit

lâ€™ID de classe

la confiance

les probabilitÃ©s complÃ¨tes

ğŸ§ª Exemple d'appel API

Commande :
1- python train_nlp.py
2- python benchmark_np.py
3- streamlit run dashboard_nlp.py 
4- LANCER API: uvicorn api_nlp:app --host 0.0.0.0 --port 8000

5- curl -X POST "http://localhost:8000/predict" \
    -H "Content-Type: application/json" \
    -d '{"text": "Apple releases a new iPhone with amazing features."}'


RÃ©ponse :

{
  "text": "Apple releases a new iPhone with amazing features.",
  "predicted_label": "Sci/Tech",
  "label_id": 3,
  "confidence": 0.9964354038238525,
  "probabilities": {
    "World": 0.001184765249490738,
    "Sports": 0.00024183574714697897,
    "Business": 0.0021379576064646244,
    "Sci/Tech": 0.9964354038238525
  }
}