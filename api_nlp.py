# api_nlp.py
# Pour lancer l'API :
# üëâ uvicorn api_nlp:app --host 0.0.0.0 --port 8000
#
# Pour tester via curl :
# curl -X POST "http://localhost:8000/predict"  -H "Content-Type: application/json"  -d '{"text": "Apple releases a new iPhone with amazing features."}'

from pathlib import Path

import torch
import torch.nn.functional as F
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ---------------------------------------------------------
# üî• Device pour faire tourner le mod√®le
# ---------------------------------------------------------
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Dossier contenant le meilleur mod√®le sauvegard√© par train_nlp.py
OUTPUT_DIR = Path("outputs")
BEST_MODEL_DIR = OUTPUT_DIR / "best_model"

# ---------------------------------------------------------
# üè∑Ô∏è Dictionnaire des labels AG News
# 0 = World, 1 = Sports, etc.
# ---------------------------------------------------------
ID2LABEL = {
    0: "World",
    1: "Sports",
    2: "Business",
    3: "Sci/Tech",
}

# ---------------------------------------------------------
# üöÄ Cr√©ation de l'application FastAPI
# ---------------------------------------------------------
app = FastAPI(title="NLP Classification API", version="1.0.0")

# ---------------------------------------------------------
# üß† Chargement du tokenizer et du meilleur mod√®le
# Ces fichiers ont √©t√© sauvegard√©s via train_nlp.py
# ---------------------------------------------------------
tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_DIR).to(DEVICE)
model.eval()   # mode inf√©rence : pas de dropout ni de gradients


# ---------------------------------------------------------
# üì® Mod√®le de donn√©es en entr√©e de l'API
# Permet de valider le JSON {"text": "..."}
# ---------------------------------------------------------
class TextInput(BaseModel):
    text: str


# ---------------------------------------------------------
# üìå Route GET pour v√©rifier que l'API fonctionne
# ---------------------------------------------------------
@app.get("/")
def root():
    return {"message": "API NLP (AG News classification)"}


# ---------------------------------------------------------
# üîÆ Route POST : pr√©diction NLP
# - On re√ßoit un texte
# - On retourne la classe pr√©dite + confiance + probas
# ---------------------------------------------------------
@app.post("/predict")
async def predict(input: TextInput):
    # 1Ô∏è‚É£ Tokenisation du texte d'entr√©e ‚Üí tenseurs pour PyTorch
    inputs = tokenizer(input.text, return_tensors="pt", truncation=True).to(DEVICE)

    # 2Ô∏è‚É£ Inf√©rence du mod√®le (pas de gradient)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits  # scores non normalis√©s
        probs = F.softmax(logits, dim=-1)[0]  # conversion en probabilit√©s

    # 3Ô∏è‚É£ S√©lection de la meilleure classe
    conf, pred_idx = torch.max(probs, dim=-1)
    label = ID2LABEL[pred_idx.item()]

    # 4Ô∏è‚É£ Construction de la r√©ponse JSON
    return {
        "text": input.text,
        "predicted_label": label,                     # nom de la classe
        "label_id": int(pred_idx.item()),             # index num√©rique
        "confidence": float(conf.item()),             # probabilit√© max
        "probabilities": {
            ID2LABEL[i]: float(p) for i, p in enumerate(probs.tolist())
        },  # probas pour toutes les classes
    }
